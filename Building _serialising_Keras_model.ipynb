{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 8982 samples, validate on 2246 samples\nEpoch 1/5\n8982/8982 [==============================] - 2s - loss: 1.3953 - val_loss: 0.9741\nEpoch 2/5\n8982/8982 [==============================] - 2s - loss: 0.7718 - val_loss: 0.8239\nEpoch 3/5\n8982/8982 [==============================] - 2s - loss: 0.5552 - val_loss: 0.8174\nEpoch 4/5\n8982/8982 [==============================] - 2s - loss: 0.4206 - val_loss: 0.8291\nEpoch 5/5\n 512/8982 [>.............................] - ETA: 2s - loss: 0.2694"
                }
            ], 
            "source": "# importing everything we need for this exercise:\n\nimport pip\n\ntry:\n    __import__('keras')\nexcept ImportError:\n    pip.main(['install', 'keras']) \n    \ntry:\n    __import__('h5py')\nexcept ImportError:\n    pip.main(['install', 'h5py']) \n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\n\nseed = 1337\nnp.random.seed(seed)\n\n# load the Reuters data set:\n\nfrom keras.datasets import reuters\n\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=seed)\nnum_classes = np.max(y_train) + 1\n\n# Using Tokenizer from Keras' text preprocessing module:\n\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n\n#  label encoding:\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n\n# model definition:\n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu',\n                input_shape =(max_words,)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation = 'softmax'))\n\n# model compilation:\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer ='adam')\n#               matrics = ['accuracy'])\n\n# model training and evaluation:\n\nbatch_size = 32 \nmodel.fit(x_train, y_train,\n          batch_size=32, epochs=5,\n          validation_data=(x_test,y_test))\nscore = model.evaluate(x_test, y_test, batch_size = 32)\n\n\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# model serialisation:\n\nmodel.save(\"model.h5\") "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!base64 model.h5 > model.h5.base64"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm -f rklib.py\n!wget https://raw.github......../"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}