{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "# importing everything we need for this exercise:\n\nimport pip\n\ntry:\n    __import__('keras')\nexcept ImportError:\n    pip.main(['install', 'keras']) \n    \ntry:\n    __import__('h5py')\nexcept ImportError:\n    pip.main(['install', 'h5py']) \n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\n\nseed = 1337\nnp.random.seed(seed)"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# load the Reuters data set:\n\nfrom keras.datasets import reuters\n\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=seed)\nnum_classes = np.max(y_train) + 1"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Using Tokenizer from Keras' text preprocessing module:\n\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#  label encoding:\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# model definition:\n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu',\n                input_shape =(max_words,)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation = 'softmax'))"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# model compilation:\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer ='adam',\n              matrics = ['accuracy'])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# model training and evaluation:\n\nbatch_size = 32 \nmodel.fit(x_train, y_train,\n          batch_size=32, epochs=5,\n          validation_data=(x_test,y_test))\nscore = model.evaluate(x_test, y_test, batch_size = 32)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "score[1]"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# model serialisation:\n\nmodel.save(\"model.h5\") "
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!base64 model.h5 > model.h5.base64"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}